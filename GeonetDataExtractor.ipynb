{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeonetDataExtractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDJPIsShfy6",
        "colab_type": "text"
      },
      "source": [
        "# **Geonet Data Extract**\n",
        "The purpose of the following code is used to extract raw ambient virbation data from collected by GNS sensors and create text files that can be read in MPIT (Operational Modal Analysis Toolbox). Outputs of Acceleration vs Time Plots and Fourier Transforms can also be generated to aid in identifying good sets of data to expedite the process.\n",
        "\n",
        "Note: The function \"analysis_select\" relates to data collected at the BNZ Building Site.\n",
        "\n",
        "Raw ambient vibration data collected from GNS can be found here:\n",
        "ftp://ftp.geonet.org.nz/strong/raw/building/\n",
        "\n",
        "**Current Code Version: 10.1.0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGK0UbiMh7vv",
        "colab_type": "text"
      },
      "source": [
        "## **Import Relevant Python Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL3eFJH3ef7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "633f1331-47e0-441e-c193-b41ddc3feb56"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "!pip install eqsig\n",
        "import eqsig\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eqsig in /usr/local/lib/python3.6/dist-packages (1.2.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from eqsig) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from eqsig) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P-J7HwJn3-u",
        "colab_type": "text"
      },
      "source": [
        "##**Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYtv6Kdw05aF",
        "colab_type": "text"
      },
      "source": [
        "###Determine Analysis Type and Global Direction\n",
        "This function processes the users choices in the analysis type (Whole Building vs One Pier [Pier 3]) and also the global direction for acceleration response that they would like to analyse. The outputted channels are the associated channels and acceleration directions in the channels that will be required to conduct their chosen analysis. The sensors were orientated with Azimuths of 37&deg; and 307&deg; which meant the X and Y directions of some of the sensors were pointing in different directions. Shown in the possible Channel/Direction combinations below is the associated combinations for the global X (Across the Piers) and Y (Along the Piers) directions that were set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2TF5cXpirV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Select channels to process depending on intended global direction and analysis type\n",
        "def dir_analysis_select(analysis_type, global_direction):\n",
        "        if analysis_type == 1 and global_direction == \"X\":\n",
        "            channels = ['4 X','5 X','6 X','7 Y','8 X','9 Y','10 Y','11 X','12 Y','13 X','14 Y','15 Y']\n",
        "        elif analysis_type == 1 and global_direction == \"Y\":\n",
        "            channels = ['4 Y','5 Y','6 Y','7 X','8 Y','9 X','10 X','11 Y','12 X','13 Y','14 X','15 X']\n",
        "        elif analysis_type == 1 and global_direction == \"Z\":\n",
        "            channels = ['4 Z','5 Z','6 Z','7 Z','8 Z','9 Z','10 Z','11 Z','12 Z','13 Z','14 Z','15 Z']\n",
        "        elif analysis_type == 2 and global_direction == \"X\":\n",
        "            channels = ['4 X','5 X','6 X','7 Y','8 X','9 Y','10 Y','11 X','15 Y']\n",
        "        elif analysis_type == 2 and global_direction == \"Y\":\n",
        "            channels = ['4 Y','5 Y','6 Y','7 X','8 Y','9 X','10 X','11 Y','15 X']\n",
        "        else:\n",
        "            channels = ['4 Z','5 Z','6 Z','7 Z','8 Z','9 Z','10 Z','11 Z','15 Z']\n",
        "        \n",
        "        return channels\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xgH9LlkE5q",
        "colab_type": "text"
      },
      "source": [
        "###Detrend acceleration data\n",
        "In the data sets there maybe systematic errors or deviations from a zero mean. This can effect the modes retrieved from signal processing and so this function finds the average acceleration value across the entire response and adjusts every data point to ensure that the average acceleration value in the response is zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoTWFqqIiZcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Takes a list of acceleration data and removes a constant offset trend.\n",
        "def detrend(raw_acc = []):\n",
        "    mean = round(sum(raw_acc)/len(raw_acc),6)\n",
        "    for z in range(len(raw_acc)):\n",
        "            raw_acc[z] = f'{raw_acc[z] - mean:.6f}'\n",
        "    return raw_acc\n",
        "       \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc5YQDo4kuUn",
        "colab_type": "text"
      },
      "source": [
        "###Generate a DataFrame\n",
        "This data frame resembles a table, which has rows of acceleration response for each increment of time (0.005sec) for a 200Hz Sample Rate, and columns representing X,Y and Z acceleration responses for each sensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RkSVl58ly5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate a data frame containing the accleration data.\n",
        "def generate_df(file_name):\n",
        "      \n",
        "    #Open raw data files\n",
        "    raw_data = open(file_name, 'r', encoding = 'latin1')\n",
        "    lines = raw_data.readlines()\n",
        "    raw_data.close()\n",
        "\n",
        "    #Store the file name:\n",
        "    file_name = file_name[:-4]\n",
        "    #Store relevant information into variables to aid in extracting the data\n",
        "    num_lines = len(lines)\n",
        "    label_length = 28\n",
        "    info_rows = 37\n",
        "    sample_rate = int((lines[20])[label_length:])\n",
        "    \n",
        "    #Channel Data\n",
        "    no_channels = (lines[21])[-21:]\n",
        "    no_channels = int(no_channels[0:2])\n",
        "\n",
        "    #Create time data for data frame\n",
        "    counter = 37\n",
        "    time_list = []\n",
        "    time = 0\n",
        "\t\n",
        "    while counter < num_lines:\n",
        "        time_list.append(\"{:.3f}\".format(time))\n",
        "        counter += 1\n",
        "        time += 1/int(sample_rate)\n",
        "    \n",
        "    timedf = {\"Time\":time_list[0:num_lines - info_rows]}\n",
        "\n",
        "    #Create the data frame with the time in the first column\n",
        "    df= pd.DataFrame(timedf)\n",
        "\n",
        "    #Establish variables due to character spacing in text file\n",
        "    j = 28\n",
        "    k = 37\n",
        "    l = 1\n",
        "\n",
        "    for channel_number in range(1,no_channels + 1):\n",
        "        counter = 0\n",
        "        value_list_x = []\n",
        "        value_list_y = []\n",
        "        value_list_z = []\n",
        "\t\t\n",
        "\t\t#Collect accelerations in each direction and store to value_list_x,y,z\n",
        "        while (counter < num_lines - info_rows):\n",
        "            value_list_x.append(round(float(lines[counter + info_rows][j : k]),6))\n",
        "            value_list_y.append(round(float(lines[counter + info_rows][j + 11 : k + 11]),6))\n",
        "            value_list_z.append(round(float(lines[counter + info_rows][j + 22: k + 22]),6))\n",
        "            counter += 1\n",
        "            \n",
        "        #Detrend Data using the established Detrending Function\n",
        "        value_list_x = detrend(value_list_x)\n",
        "        value_list_y = detrend(value_list_y)\n",
        "        value_list_z = detrend(value_list_z)\n",
        "        \n",
        "        #Append value_list_x,y,z to DataFrame  \n",
        "        df['Channel ' + str(channel_number) + ' X'] = value_list_x[0 : num_lines - info_rows]\n",
        "        df['Channel ' + str(channel_number) + ' Y'] = value_list_y[0 : num_lines - info_rows]\n",
        "        df['Channel ' + str(channel_number) + ' Z'] = value_list_z[0 : num_lines - info_rows]\n",
        "        \n",
        "        l += 3\n",
        "        j += 39\n",
        "        k += 39\n",
        "        \n",
        "    #Reverse X direction acceleration recordings for sensors orientated at 37 azimuth to align measurements  \n",
        "    azimuth37sensors = [\"Channel 7 X\", \"Channel 9 X\", \"Channel 10 X\", \"Channel 12 X\", \"Channel 14 X\", \"Channel 15 X\"]\n",
        "    \n",
        "    for sensor in azimuth37sensors:\n",
        "        df[sensor] = df[sensor].astype(float)\n",
        "        df[sensor] *= -1\n",
        "        pd.options.display.float_format = '{:.6f}'.format\n",
        "        \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiswSbmBmtiB",
        "colab_type": "text"
      },
      "source": [
        "##Output Data Frame Information into useable TXT files\n",
        "This function outputs the data frame information into .txt files that can be used in MPIT to conduct system ID. The outputted text file will have a column for time, and then subsequent appended columns showing the relevant sensor data for the chosen analysis type (Whole Building or Pier 3) and the global direction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_Fgr8IGikso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert raw GeoNet Data into tab delimited .txt files for the depending on the chosen global X,Y or Z direction.    \n",
        "def data_to_CSV(df, channel_list):\n",
        "    #Write the acceleration values into text files:\n",
        "    header = [\"Time\"]  \n",
        "    for j in channel_list:\n",
        "        header.append(\"Channel \" + j)\n",
        "        df.to_csv(file_name + \" Acceleration \" + global_direction + \".txt\", columns = header, float_format = '%.6f', index = False, sep = \"\\t\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao3lyuB8oxu3",
        "colab_type": "text"
      },
      "source": [
        "###Generate Acceleration vs Time and Fourier Transform Plots\n",
        "This function draws Acceleration vs Time and Fourier Transform plots for Channel 9 X direction acceleration response. This channel was chosen since it is on Level 5 of the BNZ building and so would experience large movements compared to channels lower in the building. These plots can help identify the days, that have acceleration response data that shows the modes accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO1xaQrIio7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Draws the Acc vs. Time + FDD\n",
        "def draw(df, file_name):\n",
        "        #Convert Data Frame to Float\n",
        "        df[0:] = df[0:].astype(float)\n",
        "                    \n",
        "        #Create an Signal object\n",
        "        acc = df['Channel 9 X'].to_numpy()\n",
        "        dt = df.iloc[1,0]\n",
        "        asig = eqsig.AccSignal(acc, dt, label='name_of_record')\n",
        "        \n",
        "        #Produce Fourier Spectrum\n",
        "        plt.plot(asig.fa_frequencies, abs(asig.fa_spectrum), c='b')\n",
        "        asig.smooth_fa_frequencies = np.logspace(-1, 1, 50)\n",
        "        plt.title('Fourier Spectrum ' + file_name[:-4])\n",
        "        plt.xlabel('Frequency [Hz]')\n",
        "        plt.ylabel('Fourier Amplitude [m/s]')\n",
        "        plt.savefig('/content/drive/Shared drives/Civil 705A B P4P Project/Data Processing/FTP Data/Ferry Terminal Data/Fourier/' + file_name + '_FFD.png', dpi=300, bbox_inches='tight')\n",
        "        \n",
        "        #Draw Acceleration vs. Time Plot\n",
        "        df[0:] = df[0:].astype(float)\n",
        "        df.plot(x='Time', y='Channel 9 X', color='r', linewidth=0.25)\n",
        "        plt.title('Time vs. Acceleration ' + file_name[:-4])\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Acceleration (ms.-2)')\n",
        "        plt.savefig('/content/drive/Shared drives/Civil 705A B P4P Project/Data Processing/FTP Data/Ferry Terminal Data/AVT/' + file_name + '.png', dpi=300, bbox_inches='tight')\n",
        "        \n",
        "        #Close plots\n",
        "        plt.close('all')\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNa6Yvqn2ERU",
        "colab_type": "text"
      },
      "source": [
        "##**Main Code**\n",
        "Ensure that the variable 'dir' is updated to be the file path of the location where the raw data to be analysed is. The folder name could be of the form '20XX CMFS'\n",
        "\n",
        "For each .cmf file:\n",
        "   1. Generate a data frame containing all selected channels.\n",
        "   2. Split accelertions into X,Y,Z direction txt files.\n",
        "   3. Draw the FDD and Acc. vs Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuUKZtPPiu6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "908ce4c7-43af-4e68-c11e-9d2736f204cc"
      },
      "source": [
        "#Ask for Analysis Type\n",
        "analysis_type = int(input(\"[1] = Whole Building Analysis,\\n[2] = Single Bay Analysis, \\nEnter Analysis Type: \"))\n",
        "global_direction = input(\"[X] = Across the three piers\\n[Y] = Along the piers towards the harbour\\n[Z] = Vertical\\nEnter Global Direction: \")\n",
        "print(\"Processing Data...\")\n",
        "\n",
        "'''\n",
        "IMPORTANT\n",
        "Update the 'dir' file path below to the location of the CMF's. Ensure that the folder name is NINE characters long i.e. 20XX CMFS\n",
        "'''\n",
        "\n",
        "dir = str(\"/content/drive/Shared drives/Civil 705A B P4P Project/Data Processing/FTP Data/Ferry Terminal Data/2015/2015 CMFS\")\n",
        "#Creates files required to save plots into\n",
        "if os.path.exists(dir + '/AVT') == 'False':\n",
        "    avt_path = os.path.join(dir[:-10],'AVT')\n",
        "    os.mkdir(avt_path)\n",
        "if os.path.exists(dir + '/Fourier') == 'False':\n",
        "    fourier_path = os.path.join(dir[:-10],'Fourier')\n",
        "    os.mkdir(fourier_path)\n",
        "\n",
        "for file in os.listdir(dir):\n",
        "    if file.endswith(\".cmf\"):\n",
        "        channels = dir_analysis_select(analysis_type, global_direction)\n",
        "        file_name = os.path.join(dir, file)\n",
        "        df = generate_df(file_name)    \n",
        "        data_to_CSV(df, channels)\n",
        "        draw(df, file) \n",
        "        print(file + \" completed...\")\n",
        "\n",
        "print(\"All files completed\")\n",
        "print(\"IMPORTANT: Remember to copy AVT and Fourier plots to appropriate folder locations, otherwise they will be overwritten in the next run\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] = Whole Building Analysis,\n",
            "[2] = Single Bay Analysis, \n",
            "Enter Analysis Type: 1\n",
            "[X] = Across the three piers\n",
            "[Y] = Along the piers towards the harbour\n",
            "[Z] = Vertical\n",
            "Enter Global Direction: X\n",
            "Processing Data...\n",
            "All files completed\n",
            "Remember to copy AVT and Fourier plots to appropriate folder locations, otherwise they will be overwritten in the next run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foJbhSIi3mWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e527c71-5d3c-4fe2-c7d2-e31bb832a7e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1KImLaC3m6s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}